1. Задание на API тесты
   Получилось сделать своеобразный фреймворк с тестами работающими в многопоточным режиме.
   Для запуска необходимо прописать:

   mvn clean test -Duser=… -Dpassword=…

Для избежания flaky тестов написал свой генератор IDшников, чтобы не было пересечений 
с id используемыми в других тестах и с тем, что уже есть в внутри нашего приложения

2. Нагрузочное тестирование метода POST
Использовал JMeter

Нагружал локально через JMeter, а также подключил плагин к Maven для автоматического запуска.
Через десктопной Jmeter анализировал результаты, тк удобнее построить графики и проанализировать отчеты, 
проще отслеживать ошибки включать и выключать необходимы тесты и анализировать результаты.
В будущем конечно можно сделать все красиво в проекте и выделить в отдельные перформанс тесты.

Запуск на через Maven на фазе verify (вначале прогоняются обычные тесты и после Performance тесты)
mvn clean verify -Duser=… -Dpassword=…

(файл TestPlan.jmx можно открыть при помощи локального JMeter и посмотреть на них включить стресс тесты.
Сделал в одном тест плане, чтобы было проще редактировать вручную)

Выводы по нагрузочному тестированию: Перед тем, как выполнять нагрузочное тестирование, 
было бы здорово определить его цели. Понять какую нагрузку мы ожидаем на наш Post метод сервиса и в зависимости 
от этого уже делать нагрузочные и стресс тесты. Сделаю еще оговорку, что все понятия «Быстро», «Хорошо» и т.д. 
Зависит от требований к системе. 


Я написал несколько тестов с разным количеством пользователей: 
user = 100     ramp-up = 1 
user = 100     ramp-up = 15
user = 100     ramp-up = 25
user = 100     ramp-up = 50
user = 100     ramp-up = 100
user = 500     ramp-up = 100

Среднее время (Average) меняет от 2 до 4 миллисекунд. Достаточно быстро проходят запросы.
Стандартное отклонение тоже достаточно мало (от 0.6 - 5) следовательно каждый запрос в среднем выполняется
примерно одинаковое количество времени.
Пропускная способность тоже удовлетворяет выставленным параметрам, например мы выставили что 100 пользователей
зайдут одновременно и пропускная способность была равна 100. 
То есть держит ровно столько пользователей, сколько и выставили.
После решил увеличить количество пользователей до 1000, затем до 2000.
Там также все отрабатывало хорошо.

Проверил на 3000 увидел, что пропускная способность стала равна ~ 2300.
Те наше приложение (развернутое локально) не может поддерживать нагрузку на метод post 
более 2300 пользователей в секунду.

Возможно все связано с ресурсами компьютера, а возможно работы приложения в целом.
При это среднее прохождение запроса 184 миллисекунды, что в целом выглядит вполне хорошо. 
Отклонение увеличилось до 50 милисекунд, но также на мой взгляд не критично. 
НО начали появляться ошибки ~ 0,27% теста упали с ошибками.
При увеличении до 4000 пропускная способность без изменений 2300.
Ошибок стало больше ~ 3,8%.
Мы видим что частично приложение начинает отказывать.
При 10 000 пользователей. Мы видим количество ошибок увеличилось до 13%.
Но что интересно, что и пропускная способность начала показывать другой резульат,
в одном из запусков стала равна 1100 те меньше, чем была.

Вывод напрашивается сам, что при большой нагрузке в нашем приложении больше ошибок 
и меньше становится пропускная способность




